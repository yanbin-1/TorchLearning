{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560aaade",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda2338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "my_Alexnet = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    \n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    \n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), \n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), \n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    \n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba977da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 5, 5])\n",
      "ReLU output shape:\t torch.Size([1, 96, 5, 5])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 2, 2])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 2, 2])\n",
      "ReLU output shape:\t torch.Size([1, 256, 2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m my_Alexnet:\n\u001b[1;32m----> 4\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(layer\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput shape:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:162\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    163\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    164\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\_jit_internal.py:423\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "# 查看每一层\n",
    "x = torch.rand(1, 1, 28, 28)\n",
    "for layer in my_Alexnet:\n",
    "    x = layer(x)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bd7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "# 加载Fashion-MNIST数据集\n",
    "def loadFashion(root, trans, batch_size, resize=None, download=False):\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(size=resize))\n",
    "\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(root=root, train=True, transform=trans, download=download)\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(root=root, train=False, transform=trans, download=download)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37899a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = loadFashion(root=\"../../Data/FashionMNIST\", trans=torchvision.transforms.ToTensor(), batch_size=128, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b665182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "torch.Size([96, 1, 28, 28])\n",
      "torch.Size([96])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看dataiter中的数据\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    for x in X:\n",
    "        plt.imshow(x.squeeze().numpy())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bfc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            net.eval()\n",
    "            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            # 改回训练模式\n",
    "            net.train()\n",
    "\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f646535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on\", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count = 0.0, 0.0, 0, 0\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            print(y_hat.shape, y.shape)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device)\n",
    "        print(\"epoch %d, loss %.4f, train acc %.3f, test acc %.3f\" % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3492a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m---> 12\u001b[0m train(net, train_iter, test_iter, optimizer, device, num_epochs)\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, test_iter, optimizer, device, num_epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m y_hat \u001b[39m=\u001b[39m net(X)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(y_hat\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m l \u001b[39m=\u001b[39m loss(y_hat, y)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:162\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    163\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    164\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\_jit_internal.py:423\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py3.10\\lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "net = my_Alexnet\n",
    "\n",
    "train_iter, test_iter = loadFashion(root=\"../../Data/FashionMNIST\", trans=torchvision.transforms.ToTensor(), batch_size=128, download=False)\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train(net, train_iter, test_iter, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
