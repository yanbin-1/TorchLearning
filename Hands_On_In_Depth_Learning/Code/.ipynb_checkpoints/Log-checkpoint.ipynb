{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a85ed3",
   "metadata": {},
   "source": [
    "## backward求导原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb45ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33897001",
   "metadata": {},
   "source": [
    "### 标量对向量求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418463ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 4.])\n"
     ]
    }
   ],
   "source": [
    "# 求出y在x处的导数\n",
    "x = torch.ones(2, requires_grad=True)  # x = [1,1]\n",
    "y = 2 * x[0] ** 3+ 2 * x[1] ** 2 \n",
    "y.backward()  # y'= ∂(2*x^2)/∂x = 6x0 + 4x1\n",
    "print(x.grad)  # x在x=[1,1]时候的导数值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c8edb",
   "metadata": {},
   "source": [
    "### 向量对向量求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9625185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在向量对向量的求导的时候如果没有传入gradients会报错\n",
    "# gradients表示各个维度上导函数前的权重\n",
    "x = torch.arange(0, 6.0, 1, requires_grad=True)  # x = [1,1,1]\n",
    "y = 2 * x ** 2\n",
    "gradients = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float)  # [0.1, 1.0, 0.0001] 表示各个维度上导函数前的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86c2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4.,  8., 12., 16., 20.])\n"
     ]
    }
   ],
   "source": [
    "# retain_graph=True表示链式求导的计算图暂时不被释放，链式求导可以重复运行，否则不能重复运行。并且导函数前的权重会累加，但是下面用的权重每次都会更新成1，所以结果不变\n",
    "y.backward(torch.ones_like(x), retain_graph=True)  # y'= ∂(2*x^2)/∂x = 4x\n",
    "# 各维度的权重分别是[0, 1, 2, 3, 4, 5]，所以结果4 * [0, 1, 2, 3, 4, 5] * [1, 1, 1, 1, 1]\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8a2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.,   8.,  24.,  48.,  80., 120.])\n"
     ]
    }
   ],
   "source": [
    "# 这里由于权重在累加，每次运行结果都会变\n",
    "y.backward(x, retain_graph=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a05fda",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee673469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e22cd2",
   "metadata": {},
   "source": [
    "### 直接下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train: [(img, label), (), ...]\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\"../Data/FashionMNIST\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\"../Data/FashionMNIST\", train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198ed97",
   "metadata": {},
   "source": [
    "### 本地读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.ImageFolder(\"../Data/FashionMNIST/train\", transform=trans)\n",
    "mnist_test = torchvision.datasets.ImageFolder(\"../Data/FashionMNIST/test\", transform=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72b951",
   "metadata": {},
   "source": [
    "## TensorDataset和DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b3a87f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[11, 22, 33],\n",
      "        [44, 55, 66]]), tensor([0, 1]))\n",
      "##############################\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "tensor([11, 22, 33]) tensor(0)\n",
      "tensor([44, 55, 66]) tensor(1)\n",
      "tensor([77, 88, 99]) tensor(2)\n",
      "##############################\n",
      " batch:1 x_data:tensor([[11, 22, 33],\n",
      "        [77, 88, 99],\n",
      "        [44, 55, 66],\n",
      "        [44, 55, 66]])  label: tensor([0, 2, 1, 1])\n",
      " batch:2 x_data:tensor([[11, 22, 33],\n",
      "        [77, 88, 99],\n",
      "        [77, 88, 99],\n",
      "        [44, 55, 66]])  label: tensor([0, 2, 2, 1])\n",
      " batch:3 x_data:tensor([[77, 88, 99],\n",
      "        [44, 55, 66],\n",
      "        [11, 22, 33],\n",
      "        [11, 22, 33]])  label: tensor([2, 1, 0, 0])\n",
      "##############################\n",
      "(tensor([11, 22, 33]), tensor(0))\n",
      "[tensor([[11, 22, 33],\n",
      "        [77, 88, 99],\n",
      "        [11, 22, 33],\n",
      "        [77, 88, 99]]), tensor([0, 2, 0, 2])]\n",
      "[tensor([[77, 88, 99],\n",
      "        [77, 88, 99],\n",
      "        [77, 88, 99],\n",
      "        [77, 88, 99]]), tensor([2, 2, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "# 数据打包\n",
    "from torch.utils.data import TensorDataset  # 相当于zip，将features和Label一一对应，传入数据的第一维度要相等，可索引\n",
    "from torch.utils.data import DataLoader  # 数据batch封装，不可索引\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([[11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99]])\n",
    "b = torch.tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
    "train_ids = TensorDataset(a, b)  # 要传tensor\n",
    "# 切片输出\n",
    "print(train_ids[0:2])\n",
    "print('#' * 30)\n",
    "# 循环取数据\n",
    "for x_train, y_label in train_ids:\n",
    "    print(x_train, y_label)\n",
    "# DataLoader进行数据封装,num_workers可以设置读取数据集的进程\n",
    "print('#' * 30)\n",
    "train_loader = DataLoader(dataset=train_ids, batch_size=4, shuffle=True, num_workers=0)\n",
    "for i, data in enumerate(train_loader, 1):  # 注意enumerate返回值有两个,一个是序号，一个是数据（包含训练数据和标签）\n",
    "    x_data, label = data\n",
    "    print(' batch:{0} x_data:{1}  label: {2}'.format(i, x_data, label))   # y data (torch tensor)\n",
    "    \n",
    "print('#' * 30)\n",
    "print(train_ids[0])\n",
    "print(next(iter(train_loader)))  # 查看第一个batch\n",
    "print(next(iter(train_loader)))  # 查看第二个batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4a665",
   "metadata": {},
   "source": [
    "## 网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0eb02",
   "metadata": {},
   "source": [
    "### 定义一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11a80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_num, output):\n",
    "        super().__init__()  # 继承父类的init\n",
    "        self.hidden = nn.Linear(input_num, output)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        return x\n",
    "    \n",
    "input_num = 2\n",
    "output_num = 1\n",
    "net = Net(input_num, output_num)\n",
    "# 自定义权重和偏置\n",
    "net.hidden.weight.data = torch.tensor([[-0.0017,  0.0118]])\n",
    "net.hidden.bias.data = torch.tensor([[0.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c05606",
   "metadata": {},
   "source": [
    "### 定义二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42860ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Linear(input_num, output_num)\n",
    ")\n",
    "net1[0].weight.data = torch.tensor([[-0.0017,  0.0118]])\n",
    "net1[0].bias.data = torch.tensor([[0.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f114a52",
   "metadata": {},
   "source": [
    "### 定义三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72aa562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, input_num, output):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Sequential(nn.Linear(input_num, output_num))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323f5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Net2(input_num, output_num)\n",
    "net2.hidden[0].weight.data = torch.tensor([[-0.0017,  0.0118]])\n",
    "net2.hidden[0].bias.data = torch.tensor([[0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68e7a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0219]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0219]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0219]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 三种定义结果一样\n",
    "print(net(torch.tensor([[1.0, 2.0]])))\n",
    "print(net1(torch.tensor([[1.0, 2.0]])))\n",
    "print(net2(torch.tensor([[1.0, 2.0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6101c0",
   "metadata": {},
   "source": [
    "### 权重初始化（防止梯度爆炸和梯度消失）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6391916",
   "metadata": {},
   "source": [
    "#### 常用的十种权重初始化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907d2a9",
   "metadata": {},
   "source": [
    "../Reference/PyTorch_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f48bcda",
   "metadata": {},
   "source": [
    "#### 方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9eb5ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始权重 tensor([[-0.0186,  0.0120,  0.0103,  ..., -0.0094,  0.0315,  0.0306],\n",
      "        [-0.0265,  0.0132, -0.0228,  ...,  0.0148,  0.0185, -0.0122],\n",
      "        [-0.0320,  0.0315, -0.0338,  ...,  0.0009,  0.0048, -0.0152],\n",
      "        ...,\n",
      "        [-0.0266, -0.0224, -0.0284,  ..., -0.0194,  0.0224,  0.0136],\n",
      "        [-0.0242, -0.0357, -0.0025,  ..., -0.0176, -0.0037, -0.0011],\n",
      "        [ 0.0303, -0.0028, -0.0330,  ...,  0.0028, -0.0047,  0.0177]])\n",
      "原始偏置 tensor([0.0065, 0.0262, 0.0049, 0.0251, 0.0071, 0.0131, 0.0164, 0.0283, 0.0192,\n",
      "        0.0208])\n",
      "修改权重 tensor([[ 0.0154, -0.0081,  0.0118,  ...,  0.0107, -0.0119, -0.0126],\n",
      "        [ 0.0067,  0.0034, -0.0047,  ...,  0.0162, -0.0002, -0.0014],\n",
      "        [-0.0070, -0.0125,  0.0061,  ...,  0.0016, -0.0030,  0.0077],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0084,  0.0037,  ...,  0.0094,  0.0052, -0.0177],\n",
      "        [-0.0359,  0.0020, -0.0019,  ...,  0.0095, -0.0184,  0.0090],\n",
      "        [ 0.0098, -0.0172, -0.0097,  ...,  0.0157,  0.0094,  0.0133]])\n",
      "修改偏置 tensor([-0.0033,  0.0080,  0.0048, -0.0163,  0.0137,  0.0010, -0.0029, -0.0031,\n",
      "         0.0052,  0.0151])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 直接展平后过全连接\n",
    "class SoftMaxNet(nn.Module):\n",
    "    def __init__(self, input_num, output_num):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_num, output_num)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        return x\n",
    "\n",
    "input_num = 784\n",
    "output_num = 10\n",
    "net = SoftMaxNet(input_num, output_num)\n",
    "for name, model in net.named_children():\n",
    "    if type(model) == nn.Sequential:\n",
    "        for m in model:\n",
    "            if type(m) == nn.Linear:\n",
    "                print(\"原始权重\", m.weight.data)\n",
    "                print(\"原始偏置\", m.bias.data)\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "                nn.init.normal_(m.bias, mean=0, std=0.01)\n",
    "                print(\"修改权重\", m.weight.data)\n",
    "                print(\"修改偏置\", m.bias.data)\n",
    "    elif type[model] == nn.Linear:\n",
    "        nn.init.normal_(model.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(m.bias, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63df806",
   "metadata": {},
   "source": [
    "#### 方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a626d21",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始权重 tensor([[ 0.0320, -0.0031, -0.0327,  ..., -0.0319, -0.0268,  0.0236],\n",
      "        [ 0.0008,  0.0235, -0.0347,  ...,  0.0255,  0.0301,  0.0339],\n",
      "        [-0.0079, -0.0001,  0.0022,  ..., -0.0182,  0.0296,  0.0336],\n",
      "        ...,\n",
      "        [ 0.0220,  0.0310,  0.0162,  ..., -0.0164, -0.0243, -0.0292],\n",
      "        [ 0.0160,  0.0005, -0.0268,  ...,  0.0113, -0.0352, -0.0064],\n",
      "        [-0.0157,  0.0231,  0.0017,  ...,  0.0352,  0.0288, -0.0298]])\n",
      "原始偏置 tensor([-8.0495e-03, -2.0037e-02, -3.4692e-03, -2.2001e-02, -1.5363e-02,\n",
      "         3.2640e-02, -2.7605e-02,  3.4867e-02,  2.1547e-02,  1.2764e-02,\n",
      "        -3.4017e-02, -1.6642e-02,  1.3973e-02, -1.4633e-02,  3.4857e-02,\n",
      "         1.4940e-02,  3.9604e-03,  3.1490e-02,  1.9545e-02,  1.1835e-02,\n",
      "         3.1879e-02,  2.8525e-02, -8.6612e-03,  8.8350e-03,  6.3228e-03,\n",
      "         1.4076e-02, -2.3187e-02, -2.5201e-03,  2.7289e-02,  5.9613e-03,\n",
      "        -4.4714e-03,  1.1179e-02, -2.3965e-04,  1.6895e-02,  1.8803e-02,\n",
      "         3.3039e-02, -1.5504e-02,  3.3519e-02,  3.4112e-02, -1.8165e-02,\n",
      "         3.3057e-02, -1.2221e-02, -2.0696e-02, -6.9908e-03, -2.2913e-03,\n",
      "         2.1522e-02,  1.4361e-02, -2.4386e-02,  1.1690e-02, -1.7657e-02,\n",
      "        -3.9985e-03,  1.2108e-02,  2.0006e-02, -2.6289e-02, -3.2421e-02,\n",
      "         5.4360e-03, -2.5960e-02, -1.5083e-02, -3.4057e-02,  2.2769e-02,\n",
      "         3.3497e-02,  1.8594e-02, -3.0098e-03,  1.0406e-02, -1.5418e-02,\n",
      "        -1.7605e-02,  3.3791e-02, -3.5371e-02, -4.3309e-03,  2.1199e-02,\n",
      "        -1.1152e-02,  1.8072e-03, -3.0917e-02,  2.4781e-02,  1.1455e-02,\n",
      "         2.4536e-02, -1.1594e-02,  2.4800e-02, -2.7557e-02, -2.4338e-02,\n",
      "        -1.7490e-02,  3.5143e-02,  2.7907e-03, -8.8780e-03,  1.0525e-02,\n",
      "        -2.7770e-02, -2.6993e-03,  1.4779e-02,  2.6181e-02, -3.0464e-03,\n",
      "        -7.8993e-03,  3.5160e-02, -8.5770e-03, -1.7610e-02,  2.9821e-02,\n",
      "         1.4668e-02,  3.1342e-02,  1.7548e-02,  1.3231e-02,  3.1754e-02,\n",
      "        -3.3151e-02,  1.1436e-02,  2.6584e-02,  3.0577e-02,  3.4059e-02,\n",
      "        -3.0729e-03,  1.8153e-02,  7.7443e-03,  3.1954e-02, -8.4240e-03,\n",
      "        -2.6607e-02, -1.2447e-02,  2.2550e-02,  2.4973e-02, -2.4063e-02,\n",
      "         2.8310e-02, -2.5642e-02,  1.8935e-02,  2.0274e-02, -2.7712e-02,\n",
      "        -7.9053e-03, -1.7131e-02,  2.4658e-03, -3.2997e-02,  1.4596e-02,\n",
      "         2.3959e-02, -8.3469e-03,  6.8281e-03, -3.3118e-02,  2.6918e-02,\n",
      "        -3.0554e-02,  1.7502e-02, -2.9396e-02, -2.2821e-02,  3.3722e-02,\n",
      "         3.8731e-03,  2.4011e-02, -3.3108e-02, -2.5610e-02, -3.3306e-02,\n",
      "        -2.1594e-02, -1.7929e-02, -2.9062e-03, -2.9876e-02, -2.3844e-02,\n",
      "        -2.1883e-02, -9.9050e-03, -2.2162e-02,  2.5934e-02, -7.2412e-03,\n",
      "        -6.3779e-03, -2.4504e-02, -1.6571e-02, -2.7495e-03, -3.0672e-02,\n",
      "         1.2184e-02,  3.3915e-03,  2.1148e-02, -1.2171e-02, -3.0875e-03,\n",
      "        -1.6673e-02, -1.4738e-02, -3.9903e-03,  1.3728e-02, -1.1621e-02,\n",
      "        -7.4292e-03,  1.3842e-02, -7.3386e-04,  3.0363e-02, -3.0020e-02,\n",
      "         3.0309e-02, -3.2390e-02, -3.2653e-02,  3.3095e-02, -2.7449e-02,\n",
      "         1.5207e-02,  7.6428e-03, -3.0909e-03, -1.8864e-02,  1.6932e-02,\n",
      "        -1.3767e-02, -5.6943e-03,  2.7199e-02, -3.2867e-02, -8.5235e-03,\n",
      "        -3.7806e-03,  6.8895e-03,  1.4113e-02, -2.1273e-02, -2.5826e-02,\n",
      "         1.6931e-02, -2.4456e-02, -2.9408e-02,  2.2581e-02,  2.6731e-02,\n",
      "         9.5711e-04,  3.5525e-02, -1.5137e-02, -2.2777e-02, -3.1029e-02,\n",
      "         1.0458e-02,  9.3243e-03, -3.1510e-02,  3.2237e-02, -1.4624e-02,\n",
      "         2.3778e-02,  1.2309e-02, -2.5778e-02,  2.5029e-02, -3.2884e-02,\n",
      "         4.8769e-03, -1.6151e-02, -2.1397e-02, -2.2521e-02,  2.4802e-02,\n",
      "         2.0057e-02,  6.7140e-03, -7.7226e-03,  2.3696e-04,  3.7261e-03,\n",
      "        -3.0061e-03, -2.8501e-02,  7.9633e-03,  1.5744e-02,  5.7516e-03,\n",
      "         2.0691e-03, -4.9748e-05,  2.7226e-02,  3.5049e-02, -6.2893e-03,\n",
      "         4.4942e-03,  6.9417e-03,  3.2859e-02,  1.1255e-02,  1.7286e-02,\n",
      "        -2.8216e-02, -1.9729e-03,  1.4064e-02,  2.5211e-02,  6.4306e-03,\n",
      "         8.1457e-03, -1.1306e-03, -1.7710e-02,  2.3714e-02,  3.5702e-03,\n",
      "        -6.8773e-03,  2.4020e-02,  2.9570e-02, -7.5456e-03,  1.4973e-02,\n",
      "        -3.4384e-02,  2.7914e-02,  3.2807e-02, -1.3346e-02,  2.7400e-02,\n",
      "         3.4967e-02])\n",
      "修改权重 tensor([[ 0.0135, -0.0044, -0.0001,  ...,  0.0169, -0.0287, -0.0046],\n",
      "        [ 0.0222, -0.0151, -0.0046,  ..., -0.0038, -0.0055, -0.0117],\n",
      "        [-0.0049,  0.0091, -0.0122,  ..., -0.0168,  0.0050, -0.0080],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0154,  0.0004,  ..., -0.0209,  0.0121,  0.0027],\n",
      "        [-0.0076,  0.0191, -0.0224,  ...,  0.0021, -0.0010,  0.0024],\n",
      "        [-0.0014, -0.0062,  0.0110,  ..., -0.0084,  0.0040, -0.0009]])\n",
      "修改偏置 tensor([-8.3182e-03,  1.7407e-02, -1.7498e-02,  8.6508e-03,  7.3178e-03,\n",
      "         1.3703e-02,  4.6384e-04, -9.6742e-03, -7.3761e-03, -4.0959e-03,\n",
      "        -5.2556e-03, -1.8141e-02, -1.1273e-02, -1.7350e-03, -2.5918e-03,\n",
      "        -1.5084e-02, -8.2815e-03, -3.7590e-03,  3.4146e-03,  2.2630e-02,\n",
      "         1.5664e-02,  1.0379e-02, -1.5132e-02,  1.8924e-02,  4.3669e-03,\n",
      "        -1.3762e-02,  1.1899e-02,  2.1504e-02,  2.6313e-04, -1.1715e-02,\n",
      "         6.4782e-03, -1.1460e-02,  1.3036e-03,  2.6856e-03,  4.1389e-03,\n",
      "         7.5224e-03,  2.1261e-03,  3.9975e-03,  1.7331e-03, -5.8252e-03,\n",
      "         1.5765e-02,  1.5570e-02,  1.7482e-03,  8.4840e-03, -7.4785e-03,\n",
      "        -1.5629e-02,  1.0335e-02,  3.2357e-03, -8.0284e-03, -7.5611e-03,\n",
      "         1.7239e-02,  3.7821e-04, -2.5350e-02,  1.0240e-02,  1.2794e-03,\n",
      "        -3.2672e-03, -2.7371e-03,  1.2379e-02, -9.8776e-03,  5.9268e-03,\n",
      "         1.0200e-02, -1.2007e-02, -7.7263e-03,  2.8447e-03,  1.2942e-02,\n",
      "         8.2467e-03,  3.7410e-03, -1.3560e-02,  2.7552e-03,  6.8502e-03,\n",
      "        -3.0402e-05, -1.9337e-02,  7.4529e-03,  4.0965e-03, -8.0646e-03,\n",
      "         8.8178e-03, -2.3820e-04,  1.1010e-03, -7.5443e-03,  6.0438e-03,\n",
      "         1.0442e-02,  1.6025e-03,  1.1100e-02, -6.1862e-03, -2.4864e-03,\n",
      "        -1.0849e-03, -8.3474e-04,  1.4560e-02, -8.9452e-03, -4.4771e-03,\n",
      "         1.6895e-03,  1.1009e-02, -2.6190e-03, -1.5620e-02, -1.0383e-02,\n",
      "        -7.9380e-03, -8.7381e-03,  9.7650e-04, -9.0724e-03,  1.6290e-03,\n",
      "        -2.6333e-03, -1.9942e-03,  1.0675e-02,  4.9730e-03,  6.8536e-03,\n",
      "         1.9839e-02, -1.8703e-02,  5.7649e-03, -3.3997e-03, -1.6499e-02,\n",
      "         2.6648e-03,  1.4186e-02,  9.5960e-03,  2.5093e-02, -1.2021e-02,\n",
      "        -6.4322e-03, -1.8871e-04, -5.5282e-03, -1.6233e-02, -1.4762e-02,\n",
      "         7.5169e-03, -1.0469e-02,  9.2419e-03, -7.0329e-03, -3.6778e-03,\n",
      "        -5.2523e-03,  1.1530e-02, -5.1819e-03, -3.0359e-03,  1.1284e-02,\n",
      "        -5.4409e-03, -1.4454e-02, -7.4301e-03, -2.0373e-02, -1.3958e-02,\n",
      "         3.2600e-03,  1.2953e-02, -4.8110e-03, -1.8519e-03,  2.1273e-03,\n",
      "         1.5493e-02, -2.2880e-02,  7.9403e-03, -5.4905e-03, -1.4341e-02,\n",
      "         6.0880e-03, -9.1790e-03, -6.7578e-03,  3.0950e-04,  1.0474e-02,\n",
      "         1.0568e-02, -6.2190e-03, -7.4168e-03,  8.3990e-03, -1.1312e-02,\n",
      "        -3.5419e-03,  1.3441e-02, -1.9899e-02,  3.1500e-03, -1.5411e-02,\n",
      "         6.7915e-03, -1.1996e-02,  5.1517e-03,  9.5738e-03,  3.6049e-03,\n",
      "         5.1429e-03,  7.8471e-03, -4.6133e-04, -2.8666e-03, -7.6173e-03,\n",
      "        -6.2250e-03,  7.2569e-03, -3.2625e-04,  3.6972e-03,  5.1988e-03,\n",
      "        -3.8249e-03,  1.9877e-02, -1.6829e-02,  1.0772e-02,  1.2611e-02,\n",
      "        -8.5666e-03,  1.1591e-03,  1.3622e-02, -5.5370e-03, -1.1638e-02,\n",
      "        -4.0360e-03,  1.9451e-02,  3.5625e-03,  1.0529e-02, -4.8535e-03,\n",
      "        -1.2887e-02,  5.9114e-03, -1.5165e-02, -4.8337e-03,  9.6833e-03,\n",
      "         3.4533e-03, -8.1940e-04,  1.0622e-04,  1.9130e-03,  3.9491e-03,\n",
      "        -8.3950e-03, -2.2848e-02,  9.4814e-03, -2.4634e-02,  1.3412e-02,\n",
      "         4.1492e-03,  1.6934e-02,  1.7476e-02, -2.2595e-02, -6.3823e-03,\n",
      "        -3.0328e-02, -1.8956e-02, -5.7130e-03, -5.3850e-03,  3.2424e-02,\n",
      "         2.0997e-03,  6.0728e-03, -6.5361e-03, -1.5789e-02, -6.9283e-03,\n",
      "        -1.3610e-02,  1.4692e-02,  1.8614e-02,  7.9522e-03,  6.7614e-03,\n",
      "        -5.3737e-03,  4.2507e-03,  1.9685e-03,  1.1138e-02, -3.0396e-02,\n",
      "        -1.0326e-02, -1.0439e-02,  6.0393e-03, -6.2699e-03, -8.1735e-03,\n",
      "         4.4679e-03,  4.6718e-03, -5.9148e-03,  1.2919e-02, -1.4804e-03,\n",
      "        -1.5908e-02,  2.0704e-03,  4.4654e-03, -1.0117e-02,  1.4491e-03,\n",
      "        -9.4748e-03, -2.4955e-02, -1.5869e-02, -4.4597e-03, -4.7481e-03,\n",
      "        -1.1319e-02, -1.1298e-03, -4.1013e-03,  8.5413e-03, -3.8777e-03,\n",
      "        -9.5703e-03])\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "        nn.init.normal_(m.bias, std=0.01)\n",
    "\n",
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(784, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))\n",
    "print(\"原始权重\", net[1].weight.data)\n",
    "print(\"原始偏置\", net[1].bias.data)\n",
    "\n",
    "net.apply(init_weights)  # apply递归初始化\n",
    "print(\"修改权重\", net[1].weight.data)\n",
    "print(\"修改偏置\", net[1].bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c94124",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd9f7e",
   "metadata": {},
   "source": [
    "### 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络模型最后一层全连接层，将输出经过 softmax 激活函数之后，再计算其与 target 的交叉熵损失\n",
    "# 'none'代表的是batch内的每个元素都会计算一个损失，返回的结果还是一个batch；\n",
    "# 'mean’代表的是是否进行平均，一个batch只返回一个；\n",
    "# 'sum’代表的是将batch内的loss相加，一个batch也是只返回一个；\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b8e96",
   "metadata": {},
   "source": [
    "## 加载本地pth模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d56237",
   "metadata": {},
   "source": [
    "### 方式一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3676e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 存整个神经网络的结构信息和模型的参数信息，save的对象是网络net\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#保存模型\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model_object,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#加载模型\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 存整个神经网络的结构信息和模型的参数信息，save的对象是网络net\n",
    "#保存模型\n",
    "torch.save(model_object,'resnet.pth')\n",
    "#加载模型\n",
    "model = torch.load('resnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e651f0",
   "metadata": {},
   "source": [
    "### 方式二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40550bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#将my_resnet模型存储为my_resnet.pth\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(my_resnet\u001b[38;5;241m.\u001b[39mstate_dict(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_resnet.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#加载resnet，模型存放在my_resnet.pth\u001b[39;00m\n\u001b[0;32m      4\u001b[0m my_resnet\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_resnet.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#将my_resnet模型存储为my_resnet.pth\n",
    "torch.save(my_resnet.state_dict(),\"my_resnet.pth\")\n",
    "#加载resnet，模型存放在my_resnet.pth\n",
    "my_resnet.load_state_dict(torch.load(\"my_resnet.pth\"))\n",
    "#其中my_resnet是my_resnet.pth对应的网络结构；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78b9943",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m li \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "li = (1, 2, 3)\n",
    "li.apply(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff205aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.448px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
