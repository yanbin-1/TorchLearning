{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    '''\n",
    "    构建相同的卷积层\n",
    "\n",
    "    num_convs: 卷积层的数量\n",
    "    in_channels: 输入通道数\n",
    "    out_channels: 输出通道数\n",
    "    '''\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels,\n",
    "                                kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积层部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(),\n",
    "        # 全连接层部分\n",
    "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "# 加载Fashion-MNIST数据集\n",
    "def loadFashion(root, trans, batch_size, resize=None, download=False):\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(size=resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(root=root, train=True, transform=trans, download=download)\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(root=root, train=False, transform=trans, download=download)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            net.eval()\n",
    "            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).sum().item()\n",
    "            # 改回训练模式\n",
    "            net.train()\n",
    "\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, loss, num_epochs, device):\n",
    "    net = net.to(device)\n",
    "    print('training on', device)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count = 0, 0, 0, 0\n",
    "        for X, y in train_iter:\n",
    "            net.train()\n",
    "            X = X.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)  # 损失函数(网络预测，标签)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "        batch_count += 1\n",
    "        n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(\"epoch %d, loss %.4f, train acc %.3f, test acc %.3f\" % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 27401337921.4519, train acc 183.375, test acc 0.100\n",
      "epoch 2, loss 2262.7291, train acc 187.562, test acc 0.100\n",
      "epoch 3, loss 2183.0598, train acc 185.844, test acc 0.100\n",
      "epoch 4, loss 2184.3004, train acc 190.125, test acc 0.100\n",
      "epoch 5, loss 2170.5317, train acc 185.750, test acc 0.100\n",
      "epoch 6, loss 2175.0172, train acc 186.188, test acc 0.100\n",
      "epoch 7, loss 2351.1770, train acc 184.844, test acc 0.100\n",
      "epoch 8, loss 2410.0323, train acc 185.312, test acc 0.100\n",
      "epoch 9, loss 2183.1861, train acc 186.406, test acc 0.100\n",
      "epoch 10, loss 2180.5256, train acc 187.500, test acc 0.100\n"
     ]
    }
   ],
   "source": [
    "# 缩减VGG网络通道数\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)\n",
    "\n",
    "batch_size = 64\n",
    "trans = [torchvision.transforms.ToTensor()]\n",
    "train_iter, test_iter = loadFashion(root=\"../../Data/FashionMNIST\", trans=trans, batch_size=batch_size, resize=224, download=False)\n",
    "\n",
    "lr = 0.05\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train(net, train_iter, test_iter, optimizer, loss, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input:\n",
      " tensor([[-0.0532,  0.9180,  0.4783, -0.4147],\n",
      "        [-1.0027,  1.0441,  0.0823,  0.1197],\n",
      "        [ 0.3484,  0.3213,  0.0848,  0.9904]])\n",
      "torch.Size([3, 4]) torch.Size([3])\n",
      "crossentropyloss_output:\n",
      " tensor(1.3234)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x_input=torch.randn(3,4)#随机生成输入 \n",
    "print('x_input:\\n',x_input) \n",
    "y_target=torch.tensor([1,2,0])#设置输出具体值 print('y_target\\n',y_target)\n",
    "print(x_input.shape, y_target.shape)\n",
    "crossentropyloss=nn.CrossEntropyLoss()\n",
    "crossentropyloss_output=crossentropyloss(x_input,y_target)\n",
    "print('crossentropyloss_output:\\n',crossentropyloss_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
